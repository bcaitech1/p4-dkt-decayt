{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6921e18-5765-43ab-adf6-2687734e8750",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret\n",
      "  Downloading pycaret-2.3.1-py3-none-any.whl (261 kB)\n",
      "\u001b[K     |████████████████████████████████| 261 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-plot\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Collecting cufflinks>=0.17.0\n",
      "  Downloading cufflinks-0.17.3.tar.gz (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.7/site-packages (from pycaret) (7.6.3)\n",
      "Collecting kmodes>=0.10.1\n",
      "  Downloading kmodes-0.11.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-1.17.0-py3-none-any.whl (14.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.2 MB 5.6 MB/s eta 0:00:01    |███▊                            | 1.7 MB 4.4 MB/s eta 0:00:03     |███████▋                        | 3.4 MB 4.4 MB/s eta 0:00:03     |█████████████████████           | 9.3 MB 4.5 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.19.5)\n",
      "Collecting mlxtend>=0.17.0\n",
      "  Downloading mlxtend-0.18.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: IPython in /opt/conda/lib/python3.7/site-packages (from pycaret) (7.16.1)\n",
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.11.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.2.4)\n",
      "Requirement already satisfied: plotly>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from pycaret) (4.14.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.0.1)\n",
      "Requirement already satisfied: scipy<=1.5.4 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.5.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from pycaret) (3.3.4)\n",
      "Collecting umap-learn\n",
      "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 6.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting Boruta\n",
      "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pyod\n",
      "  Downloading pyod-0.8.8.tar.gz (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas-profiling>=2.8.0\n",
      "  Downloading pandas_profiling-3.0.0-py2.py3-none-any.whl (248 kB)\n",
      "\u001b[K     |████████████████████████████████| 248 kB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.23.2 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.23.2)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gensim<4.0.0\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 9.2 MB/s eta 0:00:01    |▋                               | 491 kB 8.4 MB/s eta 0:00:03     |█▏                              | 849 kB 8.4 MB/s eta 0:00:03     |██                              | 1.5 MB 8.4 MB/s eta 0:00:03     |██████████████████▋             | 14.1 MB 6.2 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wordcloud\n",
      "  Downloading wordcloud-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (366 kB)\n",
      "\u001b[K     |████████████████████████████████| 366 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy<2.4.0\n",
      "  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 98 kB/s s eta 0:00:01    |█████████▎                      | 3.0 MB 10.4 MB/s eta 0:00:01     |██████████████▎                 | 4.6 MB 10.4 MB/s eta 0:00:01     |████████████████                | 5.2 MB 10.4 MB/s eta 0:00:01     |███████████████████▍            | 6.3 MB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lightgbm>=2.3.1 in /opt/conda/lib/python3.7/site-packages (from pycaret) (3.2.1)\n",
      "Collecting yellowbrick>=1.0.1\n",
      "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imbalanced-learn==0.7.0\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
      "Collecting colorlover>=0.2.1\n",
      "  Downloading colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in /opt/conda/lib/python3.7/site-packages (from cufflinks>=0.17.0->pycaret) (46.4.0.post20200518)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret) (5.1.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret) (4.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret) (5.5.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pycaret) (1.0.0)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (0.3)\n",
      "Requirement already satisfied: requests>=2.17.3 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (2.25.1)\n",
      "Collecting docker>=4.0.0\n",
      "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gunicorn; platform_system != \"Windows\"\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (1.6.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (8.0.1)\n",
      "Collecting Flask\n",
      "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.17-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 16.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gitpython>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (3.1.17)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (3.15.6)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 4.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (2021.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from mlflow->pycaret) (5.3.1)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret) (0.17.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret) (3.0.5)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret) (4.4.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret) (2.6.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret) (0.2.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from IPython->pycaret) (4.8.0)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret) (0.18.2)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (471 kB)\n",
      "\u001b[K     |████████████████████████████████| 471 kB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret) (0.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis->pycaret) (2.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pycaret) (2.8.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycaret) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycaret) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycaret) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycaret) (8.2.0)\n",
      "Requirement already satisfied: numba>=0.49 in /opt/conda/lib/python3.7/site-packages (from umap-learn->pycaret) (0.53.1)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.2.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting statsmodels\n",
      "  Using cached statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting tqdm>=4.48.2\n",
      "  Downloading tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting htmlmin>=0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "Collecting phik>=0.11.1\n",
      "  Downloading phik-0.11.2.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tangled-up-in-unicode==0.1.0\n",
      "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling>=2.8.0->pycaret) (0.4.2)\n",
      "Collecting pydantic>=1.8.1\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 18.2 MB/s eta 0:00:01    |████████▎                       | 2.6 MB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting visions[type_image_path]==0.7.1\n",
      "  Downloading visions-0.7.1-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.23.2->pycaret) (2.1.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim<4.0.0->pycaret) (5.0.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk->pycaret) (2021.4.4)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 21.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 24.3 MB/s eta 0:00:01     |██████▉                         | 2.1 MB 24.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
      "\u001b[K     |████████████████████████████████| 184 kB 26.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=2.3.1->pycaret) (0.34.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (0.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (6.4.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.1)\n",
      "Requirement already satisfied: prometheus_client in /opt/conda/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow->pycaret) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow->pycaret) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow->pycaret) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow->pycaret) (2.10)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker>=4.0.0->mlflow->pycaret) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from click>=7.0->mlflow->pycaret) (3.10.0)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from sqlalchemy->mlflow->pycaret) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow->pycaret) (3.7.4.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow->pycaret) (4.0.7)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->IPython->pycaret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->pycaret) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->pyLDAvis->pycaret) (1.1.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.49->umap-learn->pycaret) (0.36.0)\n",
      "Collecting patsy>=0.5\n",
      "  Using cached patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (21.2.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (2.5.1)\n",
      "Collecting multimethod==1.4\n",
      "  Downloading multimethod-1.4-py2.py3-none-any.whl (7.3 kB)\n",
      "Collecting bottleneck\n",
      "  Downloading Bottleneck-1.3.2.tar.gz (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting imagehash; extra == \"type_image_path\"\n",
      "  Downloading ImageHash-4.2.0-py2.py3-none-any.whl (295 kB)\n",
      "\u001b[K     |████████████████████████████████| 295 kB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (0.17.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (6.0.7)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.10.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (22.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click>=7.0->mlflow->pycaret) (3.4.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret) (4.0.0)\n",
      "Collecting PyWavelets\n",
      "  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 29.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.14.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.10)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.9)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (2.20)\n",
      "Building wheels for collected packages: cufflinks, pyLDAvis, umap-learn, pyod, prometheus-flask-exporter, databricks-cli, alembic, pynndescent, htmlmin, phik, bottleneck\n",
      "  Building wheel for cufflinks (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cufflinks: filename=cufflinks-0.17.3-py3-none-any.whl size=67921 sha256=57f22b4d5fd0222e4a6bd54722b43fca7c952c7ab69f90a34925d6966681da1c\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/e1/27/13/3fe67fa7ea7be444b831d117220b3b586b872c9acd4df480d0\n",
      "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136897 sha256=60e7ac8a5f84013c9945d76157790e3a7d91f98686139c989f8c9fe29320b955\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76566 sha256=d9b25edce5b6591360af59d8ab4abeefd6baf93a7da75488bc636242d9088945\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\n",
      "  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyod: filename=pyod-0.8.8-py3-none-any.whl size=116965 sha256=5782c3ee7e6cb4291525c19e96e70d2c4db15c3e10c0aa32b0419d4ee0ad5c92\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/77/59/4c/18e7ef198e2c737674b0bd8b6fa0fb1163c83ecc4e622fbda4\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17398 sha256=430f91b29af7649813965c64494cd017164f208a19b071e10fb97338a5ee134c\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100555 sha256=1d7b3aef8764879dbebdeff5a2d3c6c69dbb377376256b7d5c685efd6541bbe3\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/3b/60/14/6930445b08959fbdf4e3029bac7e1f2cccb2e94df8afa00b29\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158154 sha256=036caa024659053f1cf8206cc1ed6b0dca03044b4a5044cd610207afb3e37443\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.2-py3-none-any.whl size=51348 sha256=d874b2c5dbd765b07dfdffe8f62d85f00f4a2d40b04cc0a61509ad1eb4328540\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/62/0b/55/40d651c5a4106ea9ce68d014335a1c7bf059530722c0107b15\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27084 sha256=84b2f587c5a328771fc09a1f00a345568f173cec4bb03accec5ebe0194521a93\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n",
      "  Building wheel for phik (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for phik: filename=phik-0.11.2-py3-none-any.whl size=1107412 sha256=2ef5b23a6d5ce2161d0e45ecaf74ef7f200b096d387fe1a317f85f003e41a8b2\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/40/98/a3/b654f24edcdcdb87d1f70d65a506fcfdf15289db129c594bcd\n",
      "  Building wheel for bottleneck (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bottleneck: filename=Bottleneck-1.3.2-cp37-cp37m-linux_x86_64.whl size=334817 sha256=521fec8131798969122b6676af4bf9447e64dec0b1d4283453ba041eefd25c67\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/87/85/9c/a325c89ff0498660ef8a335fb4b3912939c273ea4f094af29f\n",
      "Successfully built cufflinks pyLDAvis umap-learn pyod prometheus-flask-exporter databricks-cli alembic pynndescent htmlmin phik bottleneck\n",
      "\u001b[31mERROR: flask 2.0.1 has requirement Jinja2>=3.0, but you'll have jinja2 2.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pyldavis 3.3.1 has requirement numpy>=1.20.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scikit-plot, colorlover, cufflinks, kmodes, itsdangerous, Werkzeug, Flask, prometheus-flask-exporter, docker, gunicorn, sqlparse, querystring-parser, sqlalchemy, databricks-cli, Mako, python-editor, alembic, mlflow, mlxtend, funcy, numexpr, gensim, pyLDAvis, pynndescent, umap-learn, Boruta, patsy, statsmodels, pyod, tqdm, htmlmin, phik, tangled-up-in-unicode, pydantic, multimethod, bottleneck, PyWavelets, imagehash, visions, pandas-profiling, nltk, textblob, wordcloud, cymem, murmurhash, wasabi, preshed, catalogue, plac, srsly, blis, thinc, spacy, yellowbrick, imbalanced-learn, pycaret\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.0.1\n",
      "    Uninstalling gensim-4.0.1:\n",
      "      Successfully uninstalled gensim-4.0.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.46.0\n",
      "    Uninstalling tqdm-4.46.0:\n",
      "      Successfully uninstalled tqdm-4.46.0\n",
      "Successfully installed Boruta-0.3 Flask-2.0.1 Mako-1.1.4 PyWavelets-1.1.1 Werkzeug-2.0.1 alembic-1.4.1 blis-0.7.4 bottleneck-1.3.2 catalogue-1.0.0 colorlover-0.3.0 cufflinks-0.17.3 cymem-2.0.5 databricks-cli-0.14.3 docker-5.0.0 funcy-1.16 gensim-3.8.3 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.0 imbalanced-learn-0.7.0 itsdangerous-2.0.1 kmodes-0.11.0 mlflow-1.17.0 mlxtend-0.18.0 multimethod-1.4 murmurhash-1.0.5 nltk-3.6.2 numexpr-2.7.3 pandas-profiling-3.0.0 patsy-0.5.1 phik-0.11.2 plac-1.1.3 preshed-3.0.5 prometheus-flask-exporter-0.18.2 pyLDAvis-3.3.1 pycaret-2.3.1 pydantic-1.8.2 pynndescent-0.5.2 pyod-0.8.8 python-editor-1.0.4 querystring-parser-1.2.4 scikit-plot-0.3.7 spacy-2.3.7 sqlalchemy-1.4.17 sqlparse-0.4.1 srsly-1.0.5 statsmodels-0.12.2 tangled-up-in-unicode-0.1.0 textblob-0.15.3 thinc-7.4.5 tqdm-4.61.0 umap-learn-0.5.1 visions-0.7.1 wasabi-0.8.2 wordcloud-1.8.1 yellowbrick-1.3.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8a0698-1eb5-44f9-86c0-a6d6836c99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from pycaret.classification import *\n",
    "from pycaret.utils import check_metric\n",
    "from datetime import timedelta, timezone, datetime\n",
    "import torch\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1100571d-aca5-4b67-b8c4-dec53849225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setSeeds(seed = 42):\n",
    "    # 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)    \n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "setSeeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d1455a-89f8-47ec-8aea-04f22e34fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_split_user(df):\n",
    "    new_df = df.copy()\n",
    "    new_df[\"newUserID\"] = df['assessmentItemID'].apply(lambda x:x[:3]) + df['userID'].astype(str)\n",
    "    return new_df\n",
    "\n",
    "def get_remain_test_data(df_test):\n",
    "    get_new_id = set(df_test.loc[df_test.answerCode == -1, 'newUserID'])    \n",
    "    test_data = df_test[df_test.newUserID.isin(get_new_id)]\n",
    "    remain_data = df_test.drop(test_data.index)\n",
    "    return test_data, remain_data\n",
    "# time convert\n",
    "def convert_time(s):\n",
    "    timestamp = time.mktime(datetime.strptime(s, '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "    return int(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c763560-945d-4643-b9fd-593ba0396831",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/opt/ml/input/data/train_dataset/train_data.csv'\n",
    "test_path = '/opt/ml/input/data/train_dataset/test_data.csv'\n",
    "\n",
    "df_train_ori = pd.read_csv(train_path) \n",
    "df_test_ori = pd.read_csv(test_path)\n",
    "\n",
    "df_train = feature_split_user(df_train_ori)\n",
    "df_test = feature_split_user(df_test_ori)\n",
    "\n",
    "df_test_shift = df_test[df_test['userID'] != df_test['userID'].shift(-1)] # 맞춰야하는 row만 모아놓은 것\n",
    "df_test, remain_data = get_remain_test_data(df_test)\n",
    "df_train = pd.concat([df_train, remain_data])\n",
    "\n",
    "df_train['Timestamp'] = df_train['Timestamp'].apply(convert_time)\n",
    "df_test['Timestamp'] = df_test['Timestamp'].apply(convert_time)\n",
    "\n",
    "df_train_test = pd.concat([df_train, df_test['answerCode'], df_test[df_test['answerCode'] != -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b45865c-f234-4eb6-b707-c53130c80938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trian에서 각 문제 평균 뽑기\n",
    "testId_mean_sum = df_train_test.groupby(['testId'])['answerCode'].agg(['mean','sum']).to_dict()\n",
    "assessmentItemID_mean_sum = df_train_test.groupby(['assessmentItemID'])['answerCode'].agg(['mean', 'sum']).to_dict()\n",
    "KnowledgeTag_mean_sum = df_train_test.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d49fab-3bed-431d-812b-19692d91d801",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new user id 겹치는거 없음 확인\n",
    "s1 = set(df_test.loc[:, 'userID'])\n",
    "s2 = set(df_train.loc[:, 'userID'])\n",
    "# s1 & s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6a692-d78e-4978-b1de-088a7681d7a3",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "### 한번만 실행되도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5cc7ad-d830-4dc7-834a-df03296ce261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df_ori):\n",
    "    df = df_ori.copy()\n",
    "    def assessmentItemID2item(x):\n",
    "        return int(x[-3:]) - 1\n",
    "    df['item'] = df.assessmentItemID.map(assessmentItemID2item)\n",
    "    # testId별로 나오는 문제 갯수\n",
    "    item_size = df[['assessmentItemID', 'testId']].drop_duplicates().groupby('testId').size()\n",
    "    testId2maxlen = item_size.to_dict() # 중복해서 풀이할 놈들을 제거하기 위해\n",
    "    \n",
    "    item_max = df.groupby('testId')['item'].max()\n",
    "\n",
    "    # 순서대로 풀지 않은 문제의 index\n",
    "    not_order_index = item_max[item_max +1 != item_size].index    \n",
    "    not_order_test = df.loc[df.testId.isin(not_order_index)][['assessmentItemID','testId']].drop_duplicates().sort_values('assessmentItemID')\n",
    "    not_order_group = not_order_test.groupby('testId')\n",
    "\n",
    "    not_order_ID2item = {}\n",
    "    for key in not_order_group.groups:\n",
    "        for i, (k, _) in enumerate(not_order_group.get_group(key).values):\n",
    "            not_order_ID2item[k] = i\n",
    "    \n",
    "    def assessmentItemID2item_order(x):\n",
    "        if x in not_order_ID2item:\n",
    "            return int(not_order_ID2item[x])\n",
    "        return int(x[-3:]) -1\n",
    "    df['orded_item'] = df.assessmentItemID.map(assessmentItemID2item_order)\n",
    "    df_group = df.groupby(['newUserID','testId'])['answerCode']\n",
    "    #user 별 이전까지 맞춘개수, 현재까지 맞춘개수, 현재 정답률\n",
    "    df['user_correct_answer'] = df_group.transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_total_answer'] = df_group.cumcount()\n",
    "    df['user_acc'] = df['user_correct_answer'] / df['user_total_answer']\n",
    "    \n",
    "    #한 test안에서 마지막으로 푼 문제으로 부터 지난 시간\n",
    "    df['prev_timestamp'] = df.groupby('testId')['Timestamp'].shift(0) - df.groupby('testId')['Timestamp'].shift(1)\n",
    "    \n",
    "    # user 별 마지막으로 푼 tag로부터 지난 시간, NaN값은 300으로 한다.\n",
    "    prev_timestamp_ac = df.groupby(['newUserID', 'KnowledgeTag'])[['Timestamp']].shift()\n",
    "    df['diff_time_btw_KnowledgeTag_ids'] = (df['Timestamp'] - prev_timestamp_ac['Timestamp']).fillna(300)\n",
    "    \n",
    "    # 각 tag 별 마지막으로 풀었을때 정답 여부\n",
    "    prev_correct_ac = df.groupby(['newUserID', 'KnowledgeTag'])[['answerCode']].shift()        \n",
    "    df['prev_answered_correctly'] = prev_correct_ac['answerCode'].fillna(0)\n",
    "    \n",
    "    df[\"test_sum\"] = df.testId.map(testId_mean_sum['sum'])\n",
    "    df[\"test_mean\"] = df.testId.map(testId_mean_sum['mean'])\n",
    "    df[\"ItemID_sum\"] = df.assessmentItemID.map(assessmentItemID_mean_sum['sum'])\n",
    "    df[\"ItemID_mean\"] = df.assessmentItemID.map(assessmentItemID_mean_sum['mean'])\n",
    "    df[\"tag_sum\"] = df.KnowledgeTag.map(KnowledgeTag_mean_sum['sum'])\n",
    "    df[\"tag_mean\"] = df.KnowledgeTag.map(KnowledgeTag_mean_sum['mean'])\n",
    "    \n",
    "    \n",
    "    #test, Item, tag 별 상대적 정답률\n",
    "    df['relative_test_answer'] = df['answerCode'] - df['test_mean']\n",
    "    df['relative_ItemID_answer'] = df['answerCode'] - df['ItemID_mean']\n",
    "    df['relative_tag_answer'] = df['answerCode'] - df['tag_mean']\n",
    "    \n",
    "    #이동평균선 5, 10, 15, 20, 25, 30\n",
    "#     df['ma5'] = df['user_acc'].fillna(0).rolling(window=5).mean()\n",
    "#     df['ma10'] = df['user_acc'].fillna(0).rolling(window=10).mean()\n",
    "#     df['ma15'] = df['user_acc'].fillna(0).rolling(window=15).mean()\n",
    "#     df['ma20'] = df['user_acc'].fillna(0).rolling(window=20).mean()\n",
    "#     df['ma25'] = df['user_acc'].fillna(0).rolling(window=25).mean()\n",
    "#     df['ma30'] = df['user_acc'].fillna(0).rolling(window=30).mean()\n",
    "    df_group = df.groupby('newUserID')['answerCode']\n",
    "    df['user_ma5'] = df_group.transform(lambda x: x.shift(1).rolling(window=5).mean())\n",
    "    df['user_ma10'] = df_group.transform(lambda x: x.shift(1).rolling(window=10).mean())\n",
    "    df['user_ma15'] = df_group.transform(lambda x: x.shift(1).rolling(window=15).mean())\n",
    "    df['user_ma20'] = df_group.transform(lambda x: x.shift(1).rolling(window=20).mean())\n",
    "    df['user_ma25'] = df_group.transform(lambda x: x.shift(1).rolling(window=25).mean())\n",
    "    df['user_ma30'] = df_group.transform(lambda x: x.shift(1).rolling(window=30).mean())\n",
    "\n",
    "    #MACD\n",
    "    df['MACD'] = df['user_ma15'] - df['user_ma25']\n",
    "    \n",
    "    #Standard Deviation 5,10, 15, 20, 25, 30\n",
    "#     df['sd5'] = df['user_acc'].fillna(0).rolling(window=5).std()\n",
    "#     df['sd10'] = df['user_acc'].fillna(0).rolling(window=10).std()\n",
    "#     df['sd15'] = df['user_acc'].fillna(0).rolling(window=15).std()\n",
    "#     df['sd20'] = df['user_acc'].fillna(0).rolling(window=20).std()\n",
    "#     df['sd25'] = df['user_acc'].fillna(0).rolling(window=25).std()\n",
    "#     df['sd30'] = df['user_acc'].fillna(0).rolling(window=30).std()\n",
    "    df[\"user_sd5\"] = df_group.transform(lambda x: x.shift(1).rolling(window=5).std())\n",
    "    df[\"user_sd10\"] = df_group.transform(lambda x: x.shift(1).rolling(window=10).std())\n",
    "    df[\"user_sd15\"] = df_group.transform(lambda x: x.shift(1).rolling(window=15).std())\n",
    "    df[\"user_sd20\"] = df_group.transform(lambda x: x.shift(1).rolling(window=20).std())\n",
    "    df[\"user_sd25\"] = df_group.transform(lambda x: x.shift(1).rolling(window=25).std())\n",
    "    df[\"user_sd30\"] = df_group.transform(lambda x: x.shift(1).rolling(window=30).std())\n",
    "    \n",
    "    #볼린저 밴드\n",
    "    df['Upper BollingerBand'] = df['user_ma10'] + (df['user_sd10'] * 3)\n",
    "    df['Lower BollingerBand'] = df['user_ma10'] - (df['user_sd10'] * 3)\n",
    "    \n",
    "    #이전에 같은 item, tag 몇 번 풀었는지\n",
    "    df['prior_ItemID_frequency'] = df.groupby(['newUserID', 'assessmentItemID']).cumcount()\n",
    "    df['prior_tag_frequency'] = df.groupby(['newUserID', 'KnowledgeTag']).cumcount()\n",
    "    \n",
    "    df[\"grade\"] = df[\"assessmentItemID\"].apply(lambda x: x[2]).astype('category')\n",
    "    #망각 곡선TOD\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eeccfc7-af1e-4445-80c8-3a3ab792d950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on feature engineering.\n",
      "save dataset\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"fe_train2.csv\") and os.path.exists(\"fe_test2.csv\"):\n",
    "    FE_train = pd.read_csv(\"fe_train2.csv\")\n",
    "    FE_test = pd.read_csv(\"fe_test2.csv\")\n",
    "    FE_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    FE_test.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    print(\"cache dataset complete\")\n",
    "else:\n",
    "    print(\"working on feature engineering.\")\n",
    "    FE_train = feature_engineering(df_train)\n",
    "    FE_test = feature_engineering(df_test)\n",
    "    FE_train.to_csv('fe_train2.csv')\n",
    "    FE_test.to_csv('fe_test2.csv')\n",
    "    print(\"save dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac6e68d-e1da-495b-a469-4e5ea20eb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(df_ori):\n",
    "    df = df_ori.copy()\n",
    "    df[\"grade\"] = df[\"assessmentItemID\"].apply(lambda x: x[2]).astype('category')\n",
    "    df_group = df.groupby(['newUserID','KnowledgeTag'])['answerCode']\n",
    "    df['user_tag_cumsum'] = df_group.transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_tag_cumcount'] = df_group.cumcount()\n",
    "    df['user_tag_acc'] = df['user_tag_cumsum'] / df['user_tag_cumcount']\n",
    "    \n",
    "    return df\n",
    "FE_train = add_feature(FE_train)\n",
    "FE_test = add_feature(FE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc8038ee-9631-4370-919e-c131dc971f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_add_feature(df_ori):\n",
    "    df = df_ori.copy()\n",
    "    df_group = df.groupby('newUserID')['answerCode']\n",
    "    df['user_ma3'] = df_group.transform(lambda x: x.shift(1).rolling(window=3).mean())\n",
    "    df['user_ma8'] = df_group.transform(lambda x: x.shift(1).rolling(window=8).mean())\n",
    "    df[\"user_sd3\"] = df_group.transform(lambda x: x.shift(1).rolling(window=3).std())\n",
    "    df[\"user_sd8\"] = df_group.transform(lambda x: x.shift(1).rolling(window=8).std())\n",
    "    return df\n",
    "FE_train = add_add_feature(FE_train)\n",
    "FE_test = add_add_feature(FE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d02080c7-d1b3-4233-a541-49c62cb8f40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "       'KnowledgeTag', 'newUserID', 'item', 'orded_item',\n",
       "       'user_correct_answer', 'user_total_answer', 'user_acc',\n",
       "       'prev_timestamp', 'diff_time_btw_KnowledgeTag_ids',\n",
       "       'prev_answered_correctly', 'test_sum', 'test_mean', 'ItemID_sum',\n",
       "       'ItemID_mean', 'tag_sum', 'tag_mean', 'relative_test_answer',\n",
       "       'relative_ItemID_answer', 'relative_tag_answer', 'user_ma5',\n",
       "       'user_ma10', 'user_ma15', 'user_ma20', 'user_ma25', 'user_ma30', 'MACD',\n",
       "       'user_sd5', 'user_sd10', 'user_sd15', 'user_sd20', 'user_sd25',\n",
       "       'user_sd30', 'Upper BollingerBand', 'Lower BollingerBand',\n",
       "       'prior_ItemID_frequency', 'prior_tag_frequency', 'grade',\n",
       "       'user_tag_cumsum', 'user_tag_cumcount', 'user_tag_acc', 'user_ma3',\n",
       "       'user_ma8', 'user_sd3', 'user_sd8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c3bbf-a1fe-4346-b2fb-c9a255652515",
   "metadata": {},
   "source": [
    "## catergorical data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4de2e5e-1b3a-4488-a03c-ae5b5cde850e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9454\n",
      "9399\n",
      "9399\n",
      "**************************************************\n",
      "1537\n",
      "1526\n",
      "1526\n",
      "**************************************************\n",
      "912\n",
      "912\n",
      "912\n",
      "**************************************************\n",
      "18995\n",
      "744\n",
      "0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "a = set(FE_train.assessmentItemID)\n",
    "b = set(FE_test.assessmentItemID)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)\n",
    "\n",
    "a = set(FE_train.testId)\n",
    "b = set(FE_test.testId)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)\n",
    "\n",
    "a = set(FE_train.KnowledgeTag)\n",
    "b = set(FE_test.KnowledgeTag)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)\n",
    "\n",
    "a = set(FE_train.newUserID)\n",
    "b = set(FE_test.newUserID)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb9c5cda-5831-4794-9abf-66fcdb1639ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 시작\n",
      "newUserID처리\n",
      "assessmentItemID처리\n",
      "testId처리\n",
      "KnowledgeTag처리\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# test data와 train data를 함께 handling하기 때문에 이전과 이후의 차이가 있는지 확인\n",
    "def categori_preprocessing(PP_train, PP_test):\n",
    "    cate_cols = ['newUserID', 'assessmentItemID', 'testId', 'KnowledgeTag']  # 문항, 시험지, 문항 태그\n",
    "    PP_full = pd.concat([PP_train, PP_test])\n",
    "    \n",
    "    print(\"처리 시작\")\n",
    "    for col in cate_cols:\n",
    "        label_encoder = LabelEncoder()\n",
    "        #For UNKNOWN class\n",
    "        a = PP_full[col].unique().tolist() + ['unknown']\n",
    "        label_encoder.fit(a)\n",
    "\n",
    "        #모든 컬럼이 범주형이라고 가정\n",
    "        PP_full[col] = PP_full[col].astype(str)\n",
    "        test = label_encoder.transform(PP_full[col])\n",
    "        PP_full[col] = test\n",
    "        PP_full[col] = PP_full[col].astype('category')\n",
    "        print(col + \"처리\")\n",
    "        \n",
    "    return PP_full[:len(PP_train)], PP_full[len(PP_train):]\n",
    "\n",
    "PP_train, PP_test = categori_preprocessing(FE_train, FE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f71a6328-11ae-4b73-a8ca-5896349dbbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9454\n",
      "9399\n",
      "9399\n",
      "**************************************************\n",
      "1537\n",
      "1526\n",
      "1526\n",
      "**************************************************\n",
      "912\n",
      "912\n",
      "912\n",
      "**************************************************\n",
      "18995\n",
      "744\n",
      "0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "a = set(PP_train.assessmentItemID)\n",
    "b = set(PP_test.assessmentItemID)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)\n",
    "\n",
    "a = set(PP_train.testId)\n",
    "b = set(PP_test.testId)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)\n",
    "\n",
    "a = set(PP_train.KnowledgeTag)\n",
    "b = set(PP_test.KnowledgeTag)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)\n",
    "\n",
    "a = set(PP_train.newUserID)\n",
    "b = set(PP_test.newUserID)\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(a & b))\n",
    "print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0319791-4e26-42bb-9688-7823e6a622b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 없다면 다시 train test로 분배!\n",
    "df_train, df_test = PP_train, PP_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf7c9f-67c6-41c2-b2e1-5f7c10cfb4fa",
   "metadata": {},
   "source": [
    "# validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a850a70-eda6-454e-bca0-9f2f0ed0185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맞춰야하는 문항 ID 파악\n",
    "set_assessmentItemID = set(df_test.loc[df_test.answerCode == -1, 'assessmentItemID'].values) # 문제별 ID\n",
    "set_testId = set(df_test.loc[df_test.answerCode == -1, 'testId'].values) # 시험지별 ID\n",
    "set_tag = set(df_test.loc[df_test.answerCode == -1, 'KnowledgeTag'].values) # 시험지별 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09e1bef4-b246-43f0-be7c-b44af56de4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_valid_split(df_ori, train_filter=None, val_filter=\"assessmentItemID\", ratio = 0.1):\n",
    "    random.seed(0)\n",
    "    df = df_ori.copy()\n",
    "    if val_filter == \"assessmentItemID\":\n",
    "        df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.assessmentItemID.isin(set_assessmentItemID))]\n",
    "#     elif val_filter == \"testId\":\n",
    "#         df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.testId.isin(set_testId))]\n",
    "#     elif val_filter == \"KnowledgeTag\":\n",
    "#          df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.KnowledgeTag.isin(set_tag))]\n",
    "\n",
    "    df_val = df_val.sample(frac=ratio, random_state = 0)\n",
    "    \n",
    "    if train_filter == \"test\":\n",
    "        df_train = df[df['testId'] != df['testId'].shift(-1)]\n",
    "#     elif train_filter == \"user\":\n",
    "#         df_train = df[df['newUserID'] != df['newUserID'].shift(-1)]\n",
    "#     else:\n",
    "#         df_train = df\n",
    "\n",
    "\n",
    "    df_train = df_train[df_train.index.isin(df_val.index) == False]\n",
    "    print(set(df_train.index) & set(df_val.index))\n",
    "\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95b6c05a-50b1-4d9f-89bf-f235816533fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_full_valid_split(df_ori, train_filter=None, val_filter=\"assessmentItemID\", ratio = 0.1):\n",
    "    random.seed(0)\n",
    "    df = df_ori.copy()\n",
    "\n",
    "    test_shift1 = df[df.testId != df.testId.shift(1)].reset_index()\n",
    "    test_shift2 = df[df.testId != df.testId.shift(-1)].reset_index()\n",
    "    test_shift2['testTime'] =  (test_shift2['Timestamp'] - df[df.testId.shift(-1) != df.testId.shift(-2)].iloc[:-1].reset_index()['Timestamp']) / (pd.Series(test_shift2['Timestamp'].values - test_shift1['Timestamp'].values))\n",
    "    df = test_shift2.set_index('index')\n",
    "    \n",
    "    if val_filter == \"assessmentItemID\":\n",
    "        df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.assessmentItemID.isin(set_assessmentItemID))]\n",
    "    elif val_filter == \"testId\":\n",
    "        df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.testId.isin(set_testId))]\n",
    "    elif val_filter == \"KnowledgeTag\":\n",
    "         df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.KnowledgeTag.isin(set_tag))]\n",
    "\n",
    "    df_val = df_val.sample(frac=ratio, random_state = 0)\n",
    "    \n",
    "\n",
    "    \n",
    "#     if train_filter == \"test\":\n",
    "#         test_shift1 = df[df.testId != df.testId.shift(1)].reset_index()\n",
    "#         test_shift2 = df[df.testId != df.testId.shift(-1)].reset_index()\n",
    "#         test_shift2['testTime'] =  (test_shift2['Timestamp'] - df[df.testId.shift(-1) != df.testId.shift(-2)].iloc[:-1].reset_index()['Timestamp']) / (pd.Series(test_shift2['Timestamp'].values - test_shift1['Timestamp'].values))\n",
    "#         df = test_shift2.set_index('index')\n",
    "    \n",
    "\n",
    "    df_train = df[df.index.isin(df_val.index) == False]\n",
    "    print(set(df_train.index) & set(df_val.index))\n",
    "\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ead342ed-265d-407c-b57a-b85bcaa9c339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "       'KnowledgeTag', 'newUserID', 'item', 'orded_item',\n",
       "       'user_correct_answer', 'user_total_answer', 'user_acc',\n",
       "       'prev_timestamp', 'diff_time_btw_KnowledgeTag_ids',\n",
       "       'prev_answered_correctly', 'test_sum', 'test_mean', 'ItemID_sum',\n",
       "       'ItemID_mean', 'tag_sum', 'tag_mean', 'relative_test_answer',\n",
       "       'relative_ItemID_answer', 'relative_tag_answer', 'user_ma5',\n",
       "       'user_ma10', 'user_ma15', 'user_ma20', 'user_ma25', 'user_ma30', 'MACD',\n",
       "       'user_sd5', 'user_sd10', 'user_sd15', 'user_sd20', 'user_sd25',\n",
       "       'user_sd30', 'Upper BollingerBand', 'Lower BollingerBand',\n",
       "       'prior_ItemID_frequency', 'prior_tag_frequency', 'grade',\n",
       "       'user_tag_cumsum', 'user_tag_cumcount', 'user_tag_acc', 'user_ma3',\n",
       "       'user_ma8', 'user_sd3', 'user_sd8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8f667e8-49f7-4dbf-a6d4-27c5613efb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter = 'test' # test, user, none\n",
    "val_filter = \"assessmentItemID\" # assessmentItemID, testId, KnowledgeTag\n",
    "\n",
    "FEATS = ['test_sum','ItemID_sum','tag_sum',\n",
    "        'user_correct_answer', 'user_acc', # \n",
    "        'prev_timestamp', 'diff_time_btw_KnowledgeTag_ids', 'prev_answered_correctly',\n",
    "        'test_mean', 'ItemID_mean', 'tag_mean',\n",
    "        'user_ma5', 'user_ma10', 'user_ma15', 'user_ma20', 'user_ma25', 'user_ma30', \n",
    "        'user_sd5', 'user_sd10', 'user_sd15', 'user_sd20', 'user_sd25', 'user_sd30', #\n",
    "        'user_ma3', 'user_ma8',\n",
    "        'user_sd3', 'user_sd8',\n",
    "        'MACD',  'Upper BollingerBand', 'Lower BollingerBand', 'prior_ItemID_frequency', 'prior_tag_frequency', 'testTime'\n",
    "        \n",
    "        ]\n",
    "\n",
    "'''\n",
    "'relative_test_answer', 'relative_ItemID_answer', 'relative_tag_answer',\n",
    "'remained_knowledge' ,'user_total_answer', 'user_tag_cumsum', 'user_tag_cumcount','user_tag_cumcount','user_tag_acc'\n",
    "\n",
    "'''\n",
    "         \n",
    "#categorical_features = ['assessmentItemID'] # KnowledgeTag, newUserID, testId, assessmentItemID\n",
    "categorical_features = ['KnowledgeTag', 'testId', 'assessmentItemID', 'grade', 'newUserID']\n",
    "# categorical_features = []\n",
    "numeric_features = []\n",
    "FEATS = FEATS + categorical_features + numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "783853d1-2622-468b-8488-922de7697d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = PP_train, PP_test\n",
    "df_train, df_val = get_full_valid_split(df_train, train_filter, val_filter, ratio=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e6191a0-731a-44b3-a97c-bd58cd0e29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = PP_train.copy()\n",
    "# test_shift1 = df[df.testId != df.testId.shift(1)].reset_index()\n",
    "# test_shift2 = df[df.testId != df.testId.shift(-1)].reset_index()\n",
    "# test_shift2['testTime'] =  (test_shift2['Timestamp'] - df[df.testId.shift(-1) != df.testId.shift(-2)].iloc[:-1].reset_index()['Timestamp']) / (pd.Series(test_shift2['Timestamp'].values - test_shift1['Timestamp'].values))\n",
    "# # test_shift2.reset_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5fc9475a-ef76-4363-a499-68bd4afc2155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def time_process(x):\n",
    "#     if x < 0:\n",
    "#         return 0\n",
    "#     elif x > 600:\n",
    "#         return 300\n",
    "#     else:\n",
    "#         return x\n",
    "# df_train['prev_timestamp'] = df_train['prev_timestamp'].fillna(0)\n",
    "# df_train['prev_timestamp'] = df_train['prev_timestamp'].apply(time_process)\n",
    "# df_val['prev_timestamp'] = df_val['prev_timestamp'].fillna(0)\n",
    "# df_val['prev_timestamp'] = df_val['prev_timestamp'].apply(time_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246fe17-e920-4c53-b455-0ef4a7db75fe",
   "metadata": {},
   "source": [
    "# dataset 구성 & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3173f633-0c6a-4253-9708-1843c5cba8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_answer = df_train['answerCode']\n",
    "train = df_train.drop(['answerCode'], axis=1)\n",
    "\n",
    "test_answer = df_val['answerCode']\n",
    "test = df_val.drop(['answerCode'], axis=1)\n",
    "\n",
    "lgb_train = lgb.Dataset(train[FEATS], train_answer, free_raw_data=False)\n",
    "lgb_test = lgb.Dataset(test[FEATS], test_answer, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "274a6393-adab-49b0-a827-90d63a44ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'objective': 'binary', # 이진 분류\n",
    "    'boosting_type': 'gbdt', # rf, gbdt, dart, goss\n",
    "    'metric': 'auc', # 평가 지표 설정\n",
    "    'feature_fraction': 0.9, # 피처 샘플링 비율\n",
    "    'bagging_fraction': 0.8, # 데이터 샘플링 비율\n",
    "    'bagging_freq': 1,\n",
    "    'n_estimators': 1500, # 트리 개수\n",
    "    'early_stopping_rounds': 100,\n",
    "    'seed': 42,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fbf7302-7314-41bc-8e01-ff0e9fc82413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395038\n",
      "3540\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f90e101-0117-4248-9259-fd5a9fd13051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #기억 곡선 t:시간, n:문제 등장횟수, g:학년, k:가중치, 시간이 지남에 따라 기억률\n",
    "#     def forgettingcurve(t, n, g, k=4.6052):\n",
    "#         t = float(t)\n",
    "#         n = float(n)\n",
    "#         g = float(g)\n",
    "#         t = t/(41400+g*5000)\n",
    "#         return np.exp(-t/(n+1)-k)*100\n",
    "#     grade = [ele[2] for ele in df[\"assessmentItemID\"]]\n",
    "#     df[\"grade\"] = grade\n",
    "#     df[\"remained_knowledge\"] =df.apply(lambda x : forgettingcurve(x[\"diff_time_btw_KnowledgeTag_ids\"],x[\"prior_tag_frequency\"],x[\"grade\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6637a0ac-e6b3-4cf2-8e3d-1ee703444be7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 221640, number of negative: 173398\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20620\n",
      "[LightGBM] [Info] Number of data points in the train set: 395038, number of used features: 38\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.561060 -> initscore=0.245465\n",
      "[LightGBM] [Info] Start training from score 0.245465\n",
      "[100]\ttraining's binary_logloss: 0.429642\tvalid_1's binary_logloss: 0.478804\n",
      "VALID AUC : 0.8446105081828239 ACC : 0.7692090395480226\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "#                     model_params, \n",
    "                    {'objective': 'binary'}, \n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_test],\n",
    "                    verbose_eval=100,\n",
    "                    categorical_feature=categorical_features,\n",
    "                )\n",
    "\n",
    "preds = model.predict(test[FEATS])\n",
    "acc = accuracy_score(test_answer, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(test_answer, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c5fe6-78ea-40bf-a69f-270b91d78be6",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "2efbc0f1-88ea-4795-a926-4216f69e2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : ./0615_0122.csv\n"
     ]
    }
   ],
   "source": [
    "# MAKE PREDICTION\n",
    "df_test_shift = df_test[df_test['userID'] != df_test['userID'].shift(-1)] # 맞춰야하는 row만 모아놓은 것\n",
    "\n",
    "total_preds = model.predict(df_test_shift[FEATS])\n",
    "# SAVE OUTPUT\n",
    "output_dir = './'\n",
    "prediction_name = datetime.now(timezone(timedelta(hours=9))).strftime('%m%d_%H%M')\n",
    "\n",
    "write_path = os.path.join(output_dir, f\"{prediction_name}.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)    \n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ba2c2-e0aa-4009-8e16-fc1d0f640181",
   "metadata": {},
   "source": [
    "# k-fold 사용\n",
    "### user 단위로 fold\n",
    "### k-fold에는 validation이 조금 다릅니다.\n",
    "### train에서 fold로 나눠진 val set + eval_dataset의 유저 마지막 답안을 제외한 시험지의 마지막 데이터를 concat해서 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "4eb8418c-58fd-421c-8f24-9039494d4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = PP_train\n",
    "df_test = PP_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "07518967-3d96-4b84-b9c3-1cf241abed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_valset(df_train, df_test):    \n",
    "    \n",
    "    df_val = df_test[(df_test.testId != df_test.testId.shift(-1)) & (df_test.answerCode != -1)]\n",
    "    df_train = df_train[df_train.testId != df_train.testId.shift(-1)]\n",
    "    \n",
    "    return df_train, df_val\n",
    "\n",
    "df_train, df_test_val = get_eval_valset(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "e8b2605c-c2ab-4769-8b9a-833a1940e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "predicts = None\n",
    "aucs = None\n",
    "\n",
    "id_set = list(set(df_train.newUserID))\n",
    "# validation\n",
    "val_aucs = 0\n",
    "\n",
    "## validation setting\n",
    "test_val = df_test_val.drop(['answerCode'], axis=1)\n",
    "test_val_answer = df_test_val['answerCode']\n",
    "\n",
    "# MAKE PREDICTION\n",
    "df_submit = df_test[df_test['userID'] != df_test['userID'].shift(-1)] # 맞춰야하는 row만 모아놓은 것\n",
    "submit_predicts = np.zeros(df_submit.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "0d169773-ee58-4c48-a93e-1440cfda64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.copy()\n",
    "val_filter = \"assessmentItemID\"\n",
    "train_filter = \"test\"\n",
    "\n",
    "if val_filter == \"assessmentItemID\":\n",
    "    df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.assessmentItemID.isin(set_assessmentItemID))]\n",
    "elif val_filter == \"testId\":\n",
    "    df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.testId.isin(set_testId))]\n",
    "elif val_filter == \"KnowledgeTag\":\n",
    "     df_val = df[(df['newUserID'] != df['newUserID'].shift(-1)) & (df.KnowledgeTag.isin(set_tag))]\n",
    "\n",
    "if train_filter == \"test\":\n",
    "    df_train = df[df['testId'] != df['testId'].shift(-1)]\n",
    "elif train_filter == \"user\":\n",
    "    df_train = df[df['newUserID'] != df['newUserID'].shift(-1)]\n",
    "else:\n",
    "    df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "7cfdfd3d-3b86-48df-84c4-47ac0c0cff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'objective': 'binary', # 이진 분류\n",
    "    'boosting_type': 'gbdt', # rf, gbdt, dart, goss\n",
    "    'metric': 'auc', # 평가 지표 설정\n",
    "    'feature_fraction': 0.9, # 피처 샘플링 비율\n",
    "    'bagging_fraction': 0.8, # 데이터 샘플링 비율\n",
    "    'bagging_freq': 1,\n",
    "    'n_estimators': 1500, # 트리 개수\n",
    "    'early_stopping_rounds': 100,\n",
    "    'seed': 42,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "    'learning_rate': 0.015,\n",
    "    'max_depth': 15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "a6258c09-0a94-4e6d-86f7-f2560cf59a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = []\n",
    "# for fold, (train_id, val_id) in enumerate(k_fold.split(df_val)):\n",
    "#     val_data = df_val.iloc[val_id]\n",
    "#     train_data = df_train[df_train.index.isin(val_data.index) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "e8073d97-5e8f-41bc-a768-8134af8f49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845448\tvalid_1's auc: 0.836598\n",
      "[200]\ttraining's auc: 0.856462\tvalid_1's auc: 0.841181\n",
      "[300]\ttraining's auc: 0.864481\tvalid_1's auc: 0.843064\n",
      "[400]\ttraining's auc: 0.868354\tvalid_1's auc: 0.843586\n",
      "[500]\ttraining's auc: 0.870854\tvalid_1's auc: 0.843802\n",
      "[600]\ttraining's auc: 0.872785\tvalid_1's auc: 0.843887\n",
      "[700]\ttraining's auc: 0.874351\tvalid_1's auc: 0.843965\n",
      "[800]\ttraining's auc: 0.875718\tvalid_1's auc: 0.843973\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's auc: 0.874412\tvalid_1's auc: 0.843998\n",
      "VALID AUC : 0.8439981301046597 ACC : 0.7695841841470206\n",
      "\n",
      "[1] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845444\tvalid_1's auc: 0.834658\n",
      "[200]\ttraining's auc: 0.856602\tvalid_1's auc: 0.83931\n",
      "[300]\ttraining's auc: 0.864683\tvalid_1's auc: 0.841354\n",
      "[400]\ttraining's auc: 0.868519\tvalid_1's auc: 0.841983\n",
      "[500]\ttraining's auc: 0.87098\tvalid_1's auc: 0.842251\n",
      "[600]\ttraining's auc: 0.872826\tvalid_1's auc: 0.842369\n",
      "[700]\ttraining's auc: 0.87438\tvalid_1's auc: 0.842475\n",
      "[800]\ttraining's auc: 0.875735\tvalid_1's auc: 0.842521\n",
      "Early stopping, best iteration is:\n",
      "[779]\ttraining's auc: 0.875484\tvalid_1's auc: 0.84254\n",
      "VALID AUC : 0.8425403479625679 ACC : 0.7687024317802116\n",
      "\n",
      "[2] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.84542\tvalid_1's auc: 0.836283\n",
      "[200]\ttraining's auc: 0.856579\tvalid_1's auc: 0.840712\n",
      "[300]\ttraining's auc: 0.864707\tvalid_1's auc: 0.842597\n",
      "[400]\ttraining's auc: 0.86848\tvalid_1's auc: 0.843232\n",
      "[500]\ttraining's auc: 0.870959\tvalid_1's auc: 0.843496\n",
      "[600]\ttraining's auc: 0.87278\tvalid_1's auc: 0.843657\n",
      "[700]\ttraining's auc: 0.874319\tvalid_1's auc: 0.843772\n",
      "[800]\ttraining's auc: 0.875639\tvalid_1's auc: 0.843893\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttraining's auc: 0.87537\tvalid_1's auc: 0.843912\n",
      "VALID AUC : 0.8439118223278625 ACC : 0.7695270803360097\n",
      "\n",
      "[3] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845349\tvalid_1's auc: 0.837167\n",
      "[200]\ttraining's auc: 0.856395\tvalid_1's auc: 0.841553\n",
      "[300]\ttraining's auc: 0.864538\tvalid_1's auc: 0.843444\n",
      "[400]\ttraining's auc: 0.868403\tvalid_1's auc: 0.844041\n",
      "[500]\ttraining's auc: 0.870857\tvalid_1's auc: 0.844332\n",
      "[600]\ttraining's auc: 0.872701\tvalid_1's auc: 0.844539\n",
      "[700]\ttraining's auc: 0.874262\tvalid_1's auc: 0.844725\n",
      "[800]\ttraining's auc: 0.875705\tvalid_1's auc: 0.844817\n",
      "[900]\ttraining's auc: 0.876905\tvalid_1's auc: 0.844858\n",
      "[1000]\ttraining's auc: 0.878078\tvalid_1's auc: 0.844815\n",
      "Early stopping, best iteration is:\n",
      "[907]\ttraining's auc: 0.876984\tvalid_1's auc: 0.844878\n",
      "VALID AUC : 0.8448782910148273 ACC : 0.771847588991507\n",
      "\n",
      "[4] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845429\tvalid_1's auc: 0.836457\n",
      "[200]\ttraining's auc: 0.856436\tvalid_1's auc: 0.841013\n",
      "[300]\ttraining's auc: 0.864501\tvalid_1's auc: 0.843004\n",
      "[400]\ttraining's auc: 0.868251\tvalid_1's auc: 0.843485\n",
      "[500]\ttraining's auc: 0.870696\tvalid_1's auc: 0.843647\n",
      "[600]\ttraining's auc: 0.872617\tvalid_1's auc: 0.843758\n",
      "[700]\ttraining's auc: 0.874208\tvalid_1's auc: 0.843823\n",
      "[800]\ttraining's auc: 0.875583\tvalid_1's auc: 0.843883\n",
      "Early stopping, best iteration is:\n",
      "[779]\ttraining's auc: 0.875332\tvalid_1's auc: 0.843904\n",
      "VALID AUC : 0.8439041081007792 ACC : 0.7698055413746693\n",
      "\n",
      "[5] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845375\tvalid_1's auc: 0.837477\n",
      "[200]\ttraining's auc: 0.856517\tvalid_1's auc: 0.841789\n",
      "[300]\ttraining's auc: 0.8646\tvalid_1's auc: 0.843506\n",
      "[400]\ttraining's auc: 0.868437\tvalid_1's auc: 0.844123\n",
      "[500]\ttraining's auc: 0.870928\tvalid_1's auc: 0.844499\n",
      "[600]\ttraining's auc: 0.872775\tvalid_1's auc: 0.844657\n",
      "[700]\ttraining's auc: 0.874278\tvalid_1's auc: 0.844816\n",
      "[800]\ttraining's auc: 0.875657\tvalid_1's auc: 0.844942\n",
      "Early stopping, best iteration is:\n",
      "[778]\ttraining's auc: 0.875393\tvalid_1's auc: 0.844963\n",
      "VALID AUC : 0.8449633061093609 ACC : 0.7718939991646169\n",
      "\n",
      "[6] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845366\tvalid_1's auc: 0.836942\n",
      "[200]\ttraining's auc: 0.856419\tvalid_1's auc: 0.841237\n",
      "[300]\ttraining's auc: 0.864442\tvalid_1's auc: 0.843381\n",
      "[400]\ttraining's auc: 0.868314\tvalid_1's auc: 0.844038\n",
      "[500]\ttraining's auc: 0.870789\tvalid_1's auc: 0.844359\n",
      "[600]\ttraining's auc: 0.872646\tvalid_1's auc: 0.8446\n",
      "[700]\ttraining's auc: 0.874223\tvalid_1's auc: 0.844723\n",
      "[800]\ttraining's auc: 0.875528\tvalid_1's auc: 0.844839\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's auc: 0.875249\tvalid_1's auc: 0.844844\n",
      "VALID AUC : 0.8448435471896554 ACC : 0.7711050262217478\n",
      "\n",
      "[7] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845268\tvalid_1's auc: 0.837973\n",
      "[200]\ttraining's auc: 0.856346\tvalid_1's auc: 0.842694\n",
      "[300]\ttraining's auc: 0.864467\tvalid_1's auc: 0.844772\n",
      "[400]\ttraining's auc: 0.86831\tvalid_1's auc: 0.845575\n",
      "[500]\ttraining's auc: 0.870725\tvalid_1's auc: 0.845921\n",
      "[600]\ttraining's auc: 0.872554\tvalid_1's auc: 0.846082\n",
      "[700]\ttraining's auc: 0.874083\tvalid_1's auc: 0.846194\n",
      "[800]\ttraining's auc: 0.87552\tvalid_1's auc: 0.846302\n",
      "Early stopping, best iteration is:\n",
      "[781]\ttraining's auc: 0.875273\tvalid_1's auc: 0.846327\n",
      "VALID AUC : 0.846326827601581 ACC : 0.7710586160486379\n",
      "\n",
      "[8] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845611\tvalid_1's auc: 0.833787\n",
      "[200]\ttraining's auc: 0.856671\tvalid_1's auc: 0.838418\n",
      "[300]\ttraining's auc: 0.864817\tvalid_1's auc: 0.840408\n",
      "[400]\ttraining's auc: 0.86863\tvalid_1's auc: 0.8408\n",
      "[500]\ttraining's auc: 0.871121\tvalid_1's auc: 0.841076\n",
      "[600]\ttraining's auc: 0.872959\tvalid_1's auc: 0.841153\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's auc: 0.872162\tvalid_1's auc: 0.841209\n",
      "VALID AUC : 0.8412093776056448 ACC : 0.7673458021998422\n",
      "\n",
      "[9] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845488\tvalid_1's auc: 0.834429\n",
      "[200]\ttraining's auc: 0.856414\tvalid_1's auc: 0.839087\n",
      "[300]\ttraining's auc: 0.86451\tvalid_1's auc: 0.841235\n",
      "[400]\ttraining's auc: 0.868357\tvalid_1's auc: 0.841969\n",
      "[500]\ttraining's auc: 0.870828\tvalid_1's auc: 0.842337\n",
      "[600]\ttraining's auc: 0.872705\tvalid_1's auc: 0.842475\n",
      "[700]\ttraining's auc: 0.87425\tvalid_1's auc: 0.842626\n",
      "[800]\ttraining's auc: 0.875654\tvalid_1's auc: 0.842708\n",
      "[900]\ttraining's auc: 0.876893\tvalid_1's auc: 0.842659\n",
      "Early stopping, best iteration is:\n",
      "[811]\ttraining's auc: 0.875777\tvalid_1's auc: 0.842709\n",
      "VALID AUC : 0.8427091657125235 ACC : 0.7684596463544809\n",
      "\n",
      "avg AUC : 0.8439284923729462\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold, (train_id, val_id) in enumerate(k_fold.split(df_val)):\n",
    "    print(f\"[{fold}] training start !!\")\n",
    "    val_data = df_val.iloc[val_id]\n",
    "    train_data = df_train[df_train.index.isin(val_data.index) == False]\n",
    "    \n",
    "    train = train_data.drop(['answerCode'], axis=1)\n",
    "    train_answer = train_data['answerCode']\n",
    "    \n",
    "    # remain test dataset concat\n",
    "    val = val_data.drop(['answerCode'], axis=1)\n",
    "    val_answer = val_data['answerCode']\n",
    "    all_val = pd.concat([val, test_val])\n",
    "    all_val_answer = pd.concat([val_answer, test_val_answer])\n",
    "    # 이건 test dataset 사용 X\n",
    "#     all_val = val_data.drop(['answerCode'], axis=1)\n",
    "#     all_val_answer = val_data['answerCode']    \n",
    "    \n",
    "    lgb_train = lgb.Dataset(train[FEATS], train_answer, free_raw_data=False)\n",
    "    lgb_val = lgb.Dataset(all_val[FEATS], all_val_answer, free_raw_data=False)\n",
    "    \n",
    "    model = lgb.train(\n",
    "                    model_params, \n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_val],\n",
    "                    verbose_eval=100,\n",
    "                    categorical_feature=categorical_features\n",
    "                )\n",
    "\n",
    "    val_preds = model.predict(all_val[FEATS])\n",
    "    submit_preds = model.predict(df_submit[FEATS])\n",
    "    \n",
    "    val_acc = accuracy_score(all_val_answer, np.where(val_preds >= 0.5, 1, 0))\n",
    "    val_auc = roc_auc_score(all_val_answer, val_preds)\n",
    "    print(f'VALID AUC : {val_auc} ACC : {val_acc}\\n')\n",
    "    \n",
    "    val_aucs += val_auc / 10\n",
    "    submit_predicts += np.array(submit_preds) / 10\n",
    "lgb.plot_importance(model)    \n",
    "print(f\"avg AUC : {val_aucs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a2fe1f79-fb29-4266-b9bf-e5d3d3a8f577",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.841508\tvalid_1's auc: 0.823766\n",
      "[200]\ttraining's auc: 0.854607\tvalid_1's auc: 0.825559\n",
      "[300]\ttraining's auc: 0.863733\tvalid_1's auc: 0.826634\n",
      "[400]\ttraining's auc: 0.867991\tvalid_1's auc: 0.826933\n",
      "[500]\ttraining's auc: 0.870883\tvalid_1's auc: 0.827037\n",
      "[600]\ttraining's auc: 0.873042\tvalid_1's auc: 0.827163\n",
      "[700]\ttraining's auc: 0.874768\tvalid_1's auc: 0.827156\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's auc: 0.873341\tvalid_1's auc: 0.827198\n",
      "VALID AUC : 0.8271976720852543 ACC : 0.7610078016458267\n",
      "\n",
      "[1] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.841632\tvalid_1's auc: 0.824373\n",
      "[200]\ttraining's auc: 0.854597\tvalid_1's auc: 0.826151\n",
      "[300]\ttraining's auc: 0.863681\tvalid_1's auc: 0.82712\n",
      "[400]\ttraining's auc: 0.867931\tvalid_1's auc: 0.827452\n",
      "[500]\ttraining's auc: 0.870818\tvalid_1's auc: 0.827601\n",
      "[600]\ttraining's auc: 0.87302\tvalid_1's auc: 0.827776\n",
      "[700]\ttraining's auc: 0.874687\tvalid_1's auc: 0.827869\n",
      "[800]\ttraining's auc: 0.876216\tvalid_1's auc: 0.827849\n",
      "Early stopping, best iteration is:\n",
      "[745]\ttraining's auc: 0.875397\tvalid_1's auc: 0.827926\n",
      "VALID AUC : 0.8279264481069608 ACC : 0.7609915110356537\n",
      "\n",
      "[2] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.841891\tvalid_1's auc: 0.820809\n",
      "[200]\ttraining's auc: 0.854982\tvalid_1's auc: 0.822812\n",
      "[300]\ttraining's auc: 0.864099\tvalid_1's auc: 0.824015\n",
      "[400]\ttraining's auc: 0.868416\tvalid_1's auc: 0.824349\n",
      "[500]\ttraining's auc: 0.871261\tvalid_1's auc: 0.824472\n",
      "[600]\ttraining's auc: 0.873415\tvalid_1's auc: 0.824695\n",
      "[700]\ttraining's auc: 0.875073\tvalid_1's auc: 0.824685\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's auc: 0.8738\tvalid_1's auc: 0.824733\n",
      "VALID AUC : 0.8247331798055477 ACC : 0.7587576057349613\n",
      "\n",
      "[3] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.840876\tvalid_1's auc: 0.825691\n",
      "[200]\ttraining's auc: 0.853985\tvalid_1's auc: 0.827745\n",
      "[300]\ttraining's auc: 0.862979\tvalid_1's auc: 0.828659\n",
      "[400]\ttraining's auc: 0.867282\tvalid_1's auc: 0.829022\n",
      "[500]\ttraining's auc: 0.870172\tvalid_1's auc: 0.829124\n",
      "[600]\ttraining's auc: 0.872327\tvalid_1's auc: 0.829279\n",
      "[700]\ttraining's auc: 0.87405\tvalid_1's auc: 0.829336\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's auc: 0.873953\tvalid_1's auc: 0.829344\n",
      "VALID AUC : 0.8293441121897073 ACC : 0.7627728472055649\n",
      "\n",
      "[4] training start !!\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.841374\tvalid_1's auc: 0.821833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-376-08fefc5c17c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2643\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2645\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2646\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for fold, (train_id, val_id) in enumerate(k_fold.split(id_set)):\n",
    "\n",
    "#     print(f\"[{fold}] training start !!\")\n",
    "#     train_data = df_train[df_train.newUserID.isin(train_id)]    \n",
    "#     val_data = df_train[df_train.newUserID.isin(train_id) == False]  \n",
    "\n",
    "#     train = train_data.drop(['answerCode'], axis=1)\n",
    "#     train_answer = train_data['answerCode']\n",
    "    \n",
    "\n",
    "#     val = val_data.drop(['answerCode'], axis=1)\n",
    "#     val_answer = val_data['answerCode']\n",
    "#     all_val = pd.concat([val, test_val])\n",
    "#     all_val_answer = pd.concat([val_answer, test_val_answer])\n",
    "    \n",
    "    \n",
    "#     lgb_train = lgb.Dataset(train[FEATS], train_answer, free_raw_data=False)\n",
    "#     lgb_val = lgb.Dataset(all_val[FEATS], all_val_answer, free_raw_data=False)\n",
    "    \n",
    "#     model = lgb.train(\n",
    "#                     model_params, \n",
    "#                     lgb_train,\n",
    "#                     valid_sets=[lgb_train, lgb_val],\n",
    "#                     verbose_eval=100,\n",
    "#                     categorical_feature=categorical_features\n",
    "#                 )\n",
    "\n",
    "#     val_preds = model.predict(all_val[FEATS])\n",
    "#     submit_preds = model.predict(df_submit[FEATS])\n",
    "    \n",
    "#     val_acc = accuracy_score(all_val_answer, np.where(val_preds >= 0.5, 1, 0))\n",
    "#     val_auc = roc_auc_score(all_val_answer, val_preds)\n",
    "#     print(f'VALID AUC : {val_auc} ACC : {val_acc}\\n')\n",
    "    \n",
    "#     val_aucs += val_auc / 10\n",
    "#     submit_predicts += np.array(submit_preds) / 10\n",
    "# lgb.plot_importance(model)    \n",
    "# print(f\"avg AUC : {val_aucs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "b4e6d563-3823-4490-853c-b96b1f21ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : ./0615_0117.csv\n"
     ]
    }
   ],
   "source": [
    "# SAVE OUTPUT\n",
    "output_dir = './'\n",
    "prediction_name = datetime.now(timezone(timedelta(hours=9))).strftime('%m%d_%H%M')\n",
    "\n",
    "write_path = os.path.join(output_dir, f\"{prediction_name}.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)    \n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(submit_predicts):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54a3de-e926-49a9-923d-a1245b270269",
   "metadata": {},
   "source": [
    "# pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "2fd2b7d6-b0be-46af-8a50-2c9f8983c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from pycaret.utils import check_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "ed37766f-1800-4816-b210-e50a8b2ee277",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'answerCode' not in FEATS:\n",
    "    FEATS.append('answerCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "7b94e4f1-cca3-40e7-80b8-4a5fa8904204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = PP_train, PP_test\n",
    "df_train, df_val = get_full_valid_split(df_train, train_filter, val_filter, ratio=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c9885-092a-471c-ba84-7a4486625ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# def get_ideal_dtypes(df, df_test):\n",
    "#     ideal_dtypes = dict()\n",
    "    \n",
    "#     for column in df.columns:\n",
    "#         dtype = df[column].dtype\n",
    "        \n",
    "#         if dtype != object:\n",
    "#             c_min = df[column].min()\n",
    "#             c_max = df[column].max()\n",
    "\n",
    "#             # 숫자형 데이터 형식 최적화\n",
    "#             if str(dtype)[:3] == 'int':\n",
    "#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "#                     ideal_dtypes[column] = 'int8'\n",
    "#                 elif c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n",
    "#                     ideal_dtypes[column] = 'uint8'\n",
    "#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "#                     ideal_dtypes[column] = 'int16'\n",
    "#                 elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n",
    "#                     ideal_dtypes[column] = 'uint16'\n",
    "#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "#                     ideal_dtypes[column] = 'int32'\n",
    "#                 elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n",
    "#                     ideal_dtypes[column] = 'uint32'\n",
    "#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "#                     ideal_dtypes[column] = 'int64'\n",
    "#                 elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n",
    "#                     ideal_dtypes[column] = 'uint64'\n",
    "#             else:\n",
    "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                     ideal_dtypes[column] = 'float16'\n",
    "#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "#                     ideal_dtypes[column] = 'float32'\n",
    "#                 else:\n",
    "#                     ideal_dtypes[column] = 'float64'\n",
    "#         else:\n",
    "#             df_full = pd.concat([df, df_test])\n",
    "    \n",
    "#             label_encoder = LabelEncoder()\n",
    "#             #For UNKNOWN class\n",
    "#             a = df_full[column].unique().tolist() + ['unknown']\n",
    "#             label_encoder.fit(a)\n",
    "\n",
    "#             #모든 컬럼이 범주형이라고 가정\n",
    "#             df_full[column] = df_full[column].astype(str)\n",
    "#             test = label_encoder.transform(df_full[column])\n",
    "#             df_full[column] = test\n",
    "#             ideal_dtypes[column] = 'category'\n",
    "#     ideal_dtypes['KnowledgeTag'] = 'category'   \n",
    "#     df_full = df_full.astype(ideal_dtypes)\n",
    "#     return df_full[:len(df)], df_full[len(df):]\n",
    "# PP_train, PP_test = get_ideal_dtypes(FE_train, FE_test)\n",
    "# df_train, df_val = get_full_valid_split(df_train, train_filter, val_filter, ratio=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "8cfebc76-9630-475d-b5f1-436d1e3a718d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_7910f_row5_col1,#T_7910f_row9_col1,#T_7910f_row29_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_7910f_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_7910f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_7910f_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_7910f_row0_col1\" class=\"data row0 col1\" >6461</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_7910f_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "                        <td id=\"T_7910f_row1_col1\" class=\"data row1 col1\" >answerCode</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_7910f_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "                        <td id=\"T_7910f_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_7910f_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "                        <td id=\"T_7910f_row3_col1\" class=\"data row3 col1\" >0: 0, 1: 1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_7910f_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "                        <td id=\"T_7910f_row4_col1\" class=\"data row4 col1\" >(395040, 30)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_7910f_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "                        <td id=\"T_7910f_row5_col1\" class=\"data row5 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_7910f_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "                        <td id=\"T_7910f_row6_col1\" class=\"data row6 col1\" >21</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_7910f_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "                        <td id=\"T_7910f_row7_col1\" class=\"data row7 col1\" >8</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_7910f_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "                        <td id=\"T_7910f_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_7910f_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "                        <td id=\"T_7910f_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_7910f_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "                        <td id=\"T_7910f_row10_col1\" class=\"data row10 col1\" >frequency</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_7910f_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "                        <td id=\"T_7910f_row11_col1\" class=\"data row11 col1\" >(355536, 32)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_7910f_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "                        <td id=\"T_7910f_row12_col1\" class=\"data row12 col1\" >(39504, 32)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_7910f_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "                        <td id=\"T_7910f_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_7910f_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "                        <td id=\"T_7910f_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_7910f_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "                        <td id=\"T_7910f_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_7910f_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "                        <td id=\"T_7910f_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_7910f_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "                        <td id=\"T_7910f_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_7910f_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "                        <td id=\"T_7910f_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_7910f_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "                        <td id=\"T_7910f_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_7910f_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "                        <td id=\"T_7910f_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_7910f_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "                        <td id=\"T_7910f_row21_col1\" class=\"data row21 col1\" >5fb2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_7910f_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "                        <td id=\"T_7910f_row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_7910f_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "                        <td id=\"T_7910f_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_7910f_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "                        <td id=\"T_7910f_row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_7910f_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "                        <td id=\"T_7910f_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_7910f_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "                        <td id=\"T_7910f_row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_7910f_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "                        <td id=\"T_7910f_row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_7910f_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "                        <td id=\"T_7910f_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_7910f_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "                        <td id=\"T_7910f_row29_col1\" class=\"data row29 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_7910f_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "                        <td id=\"T_7910f_row30_col1\" class=\"data row30 col1\" >robust</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_7910f_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "                        <td id=\"T_7910f_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_7910f_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "                        <td id=\"T_7910f_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_7910f_row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "                        <td id=\"T_7910f_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_7910f_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "                        <td id=\"T_7910f_row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_7910f_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "                        <td id=\"T_7910f_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_7910f_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "                        <td id=\"T_7910f_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_7910f_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "                        <td id=\"T_7910f_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_7910f_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "                        <td id=\"T_7910f_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_7910f_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "                        <td id=\"T_7910f_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_7910f_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "                        <td id=\"T_7910f_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_7910f_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "                        <td id=\"T_7910f_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_7910f_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "                        <td id=\"T_7910f_row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_7910f_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "                        <td id=\"T_7910f_row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_7910f_row44_col0\" class=\"data row44 col0\" >Clustering</td>\n",
       "                        <td id=\"T_7910f_row44_col1\" class=\"data row44 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_7910f_row45_col0\" class=\"data row45 col0\" >Clustering Iteration</td>\n",
       "                        <td id=\"T_7910f_row45_col1\" class=\"data row45 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_7910f_row46_col0\" class=\"data row46 col0\" >Polynomial Features</td>\n",
       "                        <td id=\"T_7910f_row46_col1\" class=\"data row46 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_7910f_row47_col0\" class=\"data row47 col0\" >Polynomial Degree</td>\n",
       "                        <td id=\"T_7910f_row47_col1\" class=\"data row47 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_7910f_row48_col0\" class=\"data row48 col0\" >Trignometry Features</td>\n",
       "                        <td id=\"T_7910f_row48_col1\" class=\"data row48 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_7910f_row49_col0\" class=\"data row49 col0\" >Polynomial Threshold</td>\n",
       "                        <td id=\"T_7910f_row49_col1\" class=\"data row49 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_7910f_row50_col0\" class=\"data row50 col0\" >Group Features</td>\n",
       "                        <td id=\"T_7910f_row50_col1\" class=\"data row50 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_7910f_row51_col0\" class=\"data row51 col0\" >Feature Selection</td>\n",
       "                        <td id=\"T_7910f_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_7910f_row52_col0\" class=\"data row52 col0\" >Feature Selection Method</td>\n",
       "                        <td id=\"T_7910f_row52_col1\" class=\"data row52 col1\" >classic</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_7910f_row53_col0\" class=\"data row53 col0\" >Features Selection Threshold</td>\n",
       "                        <td id=\"T_7910f_row53_col1\" class=\"data row53 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_7910f_row54_col0\" class=\"data row54 col0\" >Feature Interaction</td>\n",
       "                        <td id=\"T_7910f_row54_col1\" class=\"data row54 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_7910f_row55_col0\" class=\"data row55 col0\" >Feature Ratio</td>\n",
       "                        <td id=\"T_7910f_row55_col1\" class=\"data row55 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_7910f_row56_col0\" class=\"data row56 col0\" >Interaction Threshold</td>\n",
       "                        <td id=\"T_7910f_row56_col1\" class=\"data row56 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_7910f_row57_col0\" class=\"data row57 col0\" >Fix Imbalance</td>\n",
       "                        <td id=\"T_7910f_row57_col1\" class=\"data row57 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7910f_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "                        <td id=\"T_7910f_row58_col0\" class=\"data row58 col0\" >Fix Imbalance Method</td>\n",
       "                        <td id=\"T_7910f_row58_col1\" class=\"data row58 col1\" >SMOTE</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f508aa41750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "settings = setup(data=df_train[FEATS],\n",
    "                 target='answerCode',\n",
    "                 train_size=0.9,\n",
    "                 high_cardinality_features=categorical_features,\n",
    "                 normalize=True,\n",
    "                 normalize_method='robust',\n",
    "                 use_gpu=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "9e0fdfb4-16b5-4267-95ce-8d1cfb6b6ed3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_e2411_row10_col0,#T_e2411_row10_col1,#T_e2411_row10_col2,#T_e2411_row10_col3,#T_e2411_row10_col4,#T_e2411_row10_col5,#T_e2411_row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_e2411_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e2411_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_e2411_row0_col0\" class=\"data row0 col0\" >0.7746</td>\n",
       "                        <td id=\"T_e2411_row0_col1\" class=\"data row0 col1\" >0.8459</td>\n",
       "                        <td id=\"T_e2411_row0_col2\" class=\"data row0 col2\" >0.8418</td>\n",
       "                        <td id=\"T_e2411_row0_col3\" class=\"data row0 col3\" >0.7756</td>\n",
       "                        <td id=\"T_e2411_row0_col4\" class=\"data row0 col4\" >0.8073</td>\n",
       "                        <td id=\"T_e2411_row0_col5\" class=\"data row0 col5\" >0.5369</td>\n",
       "                        <td id=\"T_e2411_row0_col6\" class=\"data row0 col6\" >0.5395</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_e2411_row1_col0\" class=\"data row1 col0\" >0.7757</td>\n",
       "                        <td id=\"T_e2411_row1_col1\" class=\"data row1 col1\" >0.8472</td>\n",
       "                        <td id=\"T_e2411_row1_col2\" class=\"data row1 col2\" >0.8405</td>\n",
       "                        <td id=\"T_e2411_row1_col3\" class=\"data row1 col3\" >0.7776</td>\n",
       "                        <td id=\"T_e2411_row1_col4\" class=\"data row1 col4\" >0.8078</td>\n",
       "                        <td id=\"T_e2411_row1_col5\" class=\"data row1 col5\" >0.5394</td>\n",
       "                        <td id=\"T_e2411_row1_col6\" class=\"data row1 col6\" >0.5418</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_e2411_row2_col0\" class=\"data row2 col0\" >0.7773</td>\n",
       "                        <td id=\"T_e2411_row2_col1\" class=\"data row2 col1\" >0.8503</td>\n",
       "                        <td id=\"T_e2411_row2_col2\" class=\"data row2 col2\" >0.8418</td>\n",
       "                        <td id=\"T_e2411_row2_col3\" class=\"data row2 col3\" >0.7790</td>\n",
       "                        <td id=\"T_e2411_row2_col4\" class=\"data row2 col4\" >0.8092</td>\n",
       "                        <td id=\"T_e2411_row2_col5\" class=\"data row2 col5\" >0.5427</td>\n",
       "                        <td id=\"T_e2411_row2_col6\" class=\"data row2 col6\" >0.5450</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_e2411_row3_col0\" class=\"data row3 col0\" >0.7713</td>\n",
       "                        <td id=\"T_e2411_row3_col1\" class=\"data row3 col1\" >0.8450</td>\n",
       "                        <td id=\"T_e2411_row3_col2\" class=\"data row3 col2\" >0.8389</td>\n",
       "                        <td id=\"T_e2411_row3_col3\" class=\"data row3 col3\" >0.7729</td>\n",
       "                        <td id=\"T_e2411_row3_col4\" class=\"data row3 col4\" >0.8045</td>\n",
       "                        <td id=\"T_e2411_row3_col5\" class=\"data row3 col5\" >0.5302</td>\n",
       "                        <td id=\"T_e2411_row3_col6\" class=\"data row3 col6\" >0.5328</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_e2411_row4_col0\" class=\"data row4 col0\" >0.7744</td>\n",
       "                        <td id=\"T_e2411_row4_col1\" class=\"data row4 col1\" >0.8463</td>\n",
       "                        <td id=\"T_e2411_row4_col2\" class=\"data row4 col2\" >0.8370</td>\n",
       "                        <td id=\"T_e2411_row4_col3\" class=\"data row4 col3\" >0.7777</td>\n",
       "                        <td id=\"T_e2411_row4_col4\" class=\"data row4 col4\" >0.8063</td>\n",
       "                        <td id=\"T_e2411_row4_col5\" class=\"data row4 col5\" >0.5370</td>\n",
       "                        <td id=\"T_e2411_row4_col6\" class=\"data row4 col6\" >0.5391</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_e2411_row5_col0\" class=\"data row5 col0\" >0.7751</td>\n",
       "                        <td id=\"T_e2411_row5_col1\" class=\"data row5 col1\" >0.8464</td>\n",
       "                        <td id=\"T_e2411_row5_col2\" class=\"data row5 col2\" >0.8420</td>\n",
       "                        <td id=\"T_e2411_row5_col3\" class=\"data row5 col3\" >0.7761</td>\n",
       "                        <td id=\"T_e2411_row5_col4\" class=\"data row5 col4\" >0.8077</td>\n",
       "                        <td id=\"T_e2411_row5_col5\" class=\"data row5 col5\" >0.5380</td>\n",
       "                        <td id=\"T_e2411_row5_col6\" class=\"data row5 col6\" >0.5406</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_e2411_row6_col0\" class=\"data row6 col0\" >0.7720</td>\n",
       "                        <td id=\"T_e2411_row6_col1\" class=\"data row6 col1\" >0.8457</td>\n",
       "                        <td id=\"T_e2411_row6_col2\" class=\"data row6 col2\" >0.8400</td>\n",
       "                        <td id=\"T_e2411_row6_col3\" class=\"data row6 col3\" >0.7732</td>\n",
       "                        <td id=\"T_e2411_row6_col4\" class=\"data row6 col4\" >0.8052</td>\n",
       "                        <td id=\"T_e2411_row6_col5\" class=\"data row6 col5\" >0.5315</td>\n",
       "                        <td id=\"T_e2411_row6_col6\" class=\"data row6 col6\" >0.5341</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_e2411_row7_col0\" class=\"data row7 col0\" >0.7778</td>\n",
       "                        <td id=\"T_e2411_row7_col1\" class=\"data row7 col1\" >0.8495</td>\n",
       "                        <td id=\"T_e2411_row7_col2\" class=\"data row7 col2\" >0.8403</td>\n",
       "                        <td id=\"T_e2411_row7_col3\" class=\"data row7 col3\" >0.7805</td>\n",
       "                        <td id=\"T_e2411_row7_col4\" class=\"data row7 col4\" >0.8093</td>\n",
       "                        <td id=\"T_e2411_row7_col5\" class=\"data row7 col5\" >0.5441</td>\n",
       "                        <td id=\"T_e2411_row7_col6\" class=\"data row7 col6\" >0.5462</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_e2411_row8_col0\" class=\"data row8 col0\" >0.7740</td>\n",
       "                        <td id=\"T_e2411_row8_col1\" class=\"data row8 col1\" >0.8473</td>\n",
       "                        <td id=\"T_e2411_row8_col2\" class=\"data row8 col2\" >0.8367</td>\n",
       "                        <td id=\"T_e2411_row8_col3\" class=\"data row8 col3\" >0.7774</td>\n",
       "                        <td id=\"T_e2411_row8_col4\" class=\"data row8 col4\" >0.8059</td>\n",
       "                        <td id=\"T_e2411_row8_col5\" class=\"data row8 col5\" >0.5362</td>\n",
       "                        <td id=\"T_e2411_row8_col6\" class=\"data row8 col6\" >0.5383</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_e2411_row9_col0\" class=\"data row9 col0\" >0.7773</td>\n",
       "                        <td id=\"T_e2411_row9_col1\" class=\"data row9 col1\" >0.8508</td>\n",
       "                        <td id=\"T_e2411_row9_col2\" class=\"data row9 col2\" >0.8424</td>\n",
       "                        <td id=\"T_e2411_row9_col3\" class=\"data row9 col3\" >0.7787</td>\n",
       "                        <td id=\"T_e2411_row9_col4\" class=\"data row9 col4\" >0.8093</td>\n",
       "                        <td id=\"T_e2411_row9_col5\" class=\"data row9 col5\" >0.5427</td>\n",
       "                        <td id=\"T_e2411_row9_col6\" class=\"data row9 col6\" >0.5451</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_e2411_row10_col0\" class=\"data row10 col0\" >0.7749</td>\n",
       "                        <td id=\"T_e2411_row10_col1\" class=\"data row10 col1\" >0.8474</td>\n",
       "                        <td id=\"T_e2411_row10_col2\" class=\"data row10 col2\" >0.8401</td>\n",
       "                        <td id=\"T_e2411_row10_col3\" class=\"data row10 col3\" >0.7769</td>\n",
       "                        <td id=\"T_e2411_row10_col4\" class=\"data row10 col4\" >0.8073</td>\n",
       "                        <td id=\"T_e2411_row10_col5\" class=\"data row10 col5\" >0.5379</td>\n",
       "                        <td id=\"T_e2411_row10_col6\" class=\"data row10 col6\" >0.5403</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e2411_level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_e2411_row11_col0\" class=\"data row11 col0\" >0.0021</td>\n",
       "                        <td id=\"T_e2411_row11_col1\" class=\"data row11 col1\" >0.0019</td>\n",
       "                        <td id=\"T_e2411_row11_col2\" class=\"data row11 col2\" >0.0019</td>\n",
       "                        <td id=\"T_e2411_row11_col3\" class=\"data row11 col3\" >0.0023</td>\n",
       "                        <td id=\"T_e2411_row11_col4\" class=\"data row11 col4\" >0.0016</td>\n",
       "                        <td id=\"T_e2411_row11_col5\" class=\"data row11 col5\" >0.0044</td>\n",
       "                        <td id=\"T_e2411_row11_col6\" class=\"data row11 col6\" >0.0043</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f508aa41b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_3941e_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3941e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_3941e_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_3941e_row0_col1\" class=\"data row0 col1\" >0.7754</td>\n",
       "                        <td id=\"T_3941e_row0_col2\" class=\"data row0 col2\" >0.8466</td>\n",
       "                        <td id=\"T_3941e_row0_col3\" class=\"data row0 col3\" >0.8385</td>\n",
       "                        <td id=\"T_3941e_row0_col4\" class=\"data row0 col4\" >0.7791</td>\n",
       "                        <td id=\"T_3941e_row0_col5\" class=\"data row0 col5\" >0.8077</td>\n",
       "                        <td id=\"T_3941e_row0_col6\" class=\"data row0 col6\" >0.5387</td>\n",
       "                        <td id=\"T_3941e_row0_col7\" class=\"data row0 col7\" >0.5408</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f508aa49890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ad2fe_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ad2fe_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_ad2fe_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_ad2fe_row0_col1\" class=\"data row0 col1\" >0.7783</td>\n",
       "                        <td id=\"T_ad2fe_row0_col2\" class=\"data row0 col2\" >0.8483</td>\n",
       "                        <td id=\"T_ad2fe_row0_col3\" class=\"data row0 col3\" >0.8399</td>\n",
       "                        <td id=\"T_ad2fe_row0_col4\" class=\"data row0 col4\" >0.7821</td>\n",
       "                        <td id=\"T_ad2fe_row0_col5\" class=\"data row0 col5\" >0.8099</td>\n",
       "                        <td id=\"T_ad2fe_row0_col6\" class=\"data row0 col6\" >0.5447</td>\n",
       "                        <td id=\"T_ad2fe_row0_col7\" class=\"data row0 col7\" >0.5467</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f508aa446d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_174df_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_174df_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_174df_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_174df_row0_col1\" class=\"data row0 col1\" >0.7839</td>\n",
       "                        <td id=\"T_174df_row0_col2\" class=\"data row0 col2\" >0.8584</td>\n",
       "                        <td id=\"T_174df_row0_col3\" class=\"data row0 col3\" >0.8453</td>\n",
       "                        <td id=\"T_174df_row0_col4\" class=\"data row0 col4\" >0.7865</td>\n",
       "                        <td id=\"T_174df_row0_col5\" class=\"data row0 col5\" >0.8148</td>\n",
       "                        <td id=\"T_174df_row0_col6\" class=\"data row0 col6\" >0.5561</td>\n",
       "                        <td id=\"T_174df_row0_col7\" class=\"data row0 col7\" >0.5582</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f508aa44d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_sum</th>\n",
       "      <th>ItemID_sum</th>\n",
       "      <th>tag_sum</th>\n",
       "      <th>user_correct_answer</th>\n",
       "      <th>user_acc</th>\n",
       "      <th>prev_timestamp</th>\n",
       "      <th>diff_time_btw_KnowledgeTag_ids</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>ItemID_mean</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>prev_answered_correctly_0.0</th>\n",
       "      <th>user_sd3_0.0</th>\n",
       "      <th>user_sd3_not_available</th>\n",
       "      <th>prior_ItemID_frequency_0</th>\n",
       "      <th>prior_ItemID_frequency_1</th>\n",
       "      <th>prior_ItemID_frequency_2</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231527</td>\n",
       "      <td>-0.896907</td>\n",
       "      <td>-0.448203</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.207547</td>\n",
       "      <td>3.246914</td>\n",
       "      <td>-0.599550</td>\n",
       "      <td>-0.809422</td>\n",
       "      <td>-0.853283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.585511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.532020</td>\n",
       "      <td>1.134021</td>\n",
       "      <td>0.306554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.433962</td>\n",
       "      <td>-0.382716</td>\n",
       "      <td>0.415792</td>\n",
       "      <td>0.715815</td>\n",
       "      <td>0.259294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.179803</td>\n",
       "      <td>-0.804124</td>\n",
       "      <td>-0.107822</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.169811</td>\n",
       "      <td>-0.209877</td>\n",
       "      <td>-0.319088</td>\n",
       "      <td>-0.689353</td>\n",
       "      <td>-0.105310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.068966</td>\n",
       "      <td>-0.154639</td>\n",
       "      <td>-0.803911</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.509434</td>\n",
       "      <td>-0.432099</td>\n",
       "      <td>-1.501539</td>\n",
       "      <td>-0.602248</td>\n",
       "      <td>-1.384152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.820203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.201970</td>\n",
       "      <td>-0.103093</td>\n",
       "      <td>-0.816596</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.132075</td>\n",
       "      <td>1.518519</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.510882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39499</th>\n",
       "      <td>0.204434</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.458245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.226415</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>0.602987</td>\n",
       "      <td>0.790214</td>\n",
       "      <td>0.689402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39500</th>\n",
       "      <td>0.487685</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.507400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.320755</td>\n",
       "      <td>-0.308642</td>\n",
       "      <td>0.369923</td>\n",
       "      <td>0.137657</td>\n",
       "      <td>0.266571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39501</th>\n",
       "      <td>-0.086207</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.484672</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.433962</td>\n",
       "      <td>-0.382716</td>\n",
       "      <td>0.249730</td>\n",
       "      <td>0.203426</td>\n",
       "      <td>0.326560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39502</th>\n",
       "      <td>0.135468</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>-0.276427</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.452830</td>\n",
       "      <td>-0.370370</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.334047</td>\n",
       "      <td>0.270828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39503</th>\n",
       "      <td>0.322660</td>\n",
       "      <td>-0.278351</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>210.924530</td>\n",
       "      <td>137.913574</td>\n",
       "      <td>0.199189</td>\n",
       "      <td>-0.541450</td>\n",
       "      <td>0.560049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39504 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_sum  ItemID_sum   tag_sum  user_correct_answer  user_acc  \\\n",
       "0      0.231527   -0.896907 -0.448203                 -1.0 -1.000000   \n",
       "1      0.532020    1.134021  0.306554                  0.0  0.500000   \n",
       "2     -0.179803   -0.804124 -0.107822                 -0.5 -0.500000   \n",
       "3     -0.068966   -0.154639 -0.803911                 -2.0 -1.500000   \n",
       "4      0.201970   -0.103093 -0.816596                 -1.5 -1.166667   \n",
       "...         ...         ...       ...                  ...       ...   \n",
       "39499  0.204434    0.793814  0.458245                  0.0  0.500000   \n",
       "39500  0.487685    0.484536  0.507400                 -1.0 -0.500000   \n",
       "39501 -0.086207    0.237113  0.484672                 -2.0 -1.500000   \n",
       "39502  0.135468    0.020619 -0.276427                 -2.0 -1.500000   \n",
       "39503  0.322660   -0.278351  0.838795                 -1.0 -0.500000   \n",
       "\n",
       "       prev_timestamp  diff_time_btw_KnowledgeTag_ids  test_mean  ItemID_mean  \\\n",
       "0            2.207547                        3.246914  -0.599550    -0.809422   \n",
       "1           -0.433962                       -0.382716   0.415792     0.715815   \n",
       "2           -0.169811                       -0.209877  -0.319088    -0.689353   \n",
       "3           -0.509434                       -0.432099  -1.501539    -0.602248   \n",
       "4           -0.132075                        1.518519   0.074324     0.179871   \n",
       "...               ...                             ...        ...          ...   \n",
       "39499       -0.226415                       -0.246914   0.602987     0.790214   \n",
       "39500       -0.320755                       -0.308642   0.369923     0.137657   \n",
       "39501       -0.433962                       -0.382716   0.249730     0.203426   \n",
       "39502       -0.452830                       -0.370370   0.005521     0.334047   \n",
       "39503      210.924530                      137.913574   0.199189    -0.541450   \n",
       "\n",
       "       tag_mean  ...     grade  prev_answered_correctly_0.0  user_sd3_0.0  \\\n",
       "0     -0.853283  ... -1.585511                          1.0           0.0   \n",
       "1      0.259294  ...  0.254778                          0.0           1.0   \n",
       "2     -0.105310  ... -0.763163                          1.0           1.0   \n",
       "3     -1.384152  ... -1.820203                          1.0           1.0   \n",
       "4      0.510882  ... -0.763163                          0.0           1.0   \n",
       "...         ...  ...       ...                          ...           ...   \n",
       "39499  0.689402  ...  0.000000                          0.0           1.0   \n",
       "39500  0.266571  ...  0.254778                          1.0           0.0   \n",
       "39501  0.326560  ...  0.059867                          1.0           1.0   \n",
       "39502  0.270828  ... -0.763163                          1.0           1.0   \n",
       "39503  0.560049  ...  0.254778                          0.0           0.0   \n",
       "\n",
       "       user_sd3_not_available  prior_ItemID_frequency_0  \\\n",
       "0                         1.0                       1.0   \n",
       "1                         0.0                       1.0   \n",
       "2                         0.0                       1.0   \n",
       "3                         0.0                       1.0   \n",
       "4                         0.0                       1.0   \n",
       "...                       ...                       ...   \n",
       "39499                     0.0                       1.0   \n",
       "39500                     1.0                       1.0   \n",
       "39501                     0.0                       1.0   \n",
       "39502                     0.0                       1.0   \n",
       "39503                     1.0                       1.0   \n",
       "\n",
       "       prior_ItemID_frequency_1  prior_ItemID_frequency_2  answerCode  Label  \\\n",
       "0                           0.0                       0.0           0      0   \n",
       "1                           0.0                       0.0           1      0   \n",
       "2                           0.0                       0.0           0      0   \n",
       "3                           0.0                       0.0           1      0   \n",
       "4                           0.0                       0.0           0      0   \n",
       "...                         ...                       ...         ...    ...   \n",
       "39499                       0.0                       0.0           1      1   \n",
       "39500                       0.0                       0.0           0      0   \n",
       "39501                       0.0                       0.0           0      0   \n",
       "39502                       0.0                       0.0           0      0   \n",
       "39503                       0.0                       0.0           0      0   \n",
       "\n",
       "        Score  \n",
       "0      0.7985  \n",
       "1      0.7088  \n",
       "2      0.8958  \n",
       "3      0.7039  \n",
       "4      0.6816  \n",
       "...       ...  \n",
       "39499  0.9191  \n",
       "39500  0.9376  \n",
       "39501  0.9778  \n",
       "39502  0.9788  \n",
       "39503  0.5821  \n",
       "\n",
       "[39504 rows x 35 columns]"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = create_model('lightgbm', sort='AUC')\n",
    "tuned_lgbm = tune_model(lgbm, optimize = 'AUC', fold = 10)\n",
    "final_lgbm = finalize_model(tuned_lgbm)\n",
    "\n",
    "predict_model(lgbm)\n",
    "predict_model(tuned_lgbm)\n",
    "predict_model(final_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "2aea84a8-ece8-48b4-ab6d-b4994a281841",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-692-5bbba3bbb77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_lgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train : {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_lgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"validation :  {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycaret/classification.py\u001b[0m in \u001b[0;36mpredict_model\u001b[0;34m(estimator, data, probability_threshold, encoded_labels, raw_score, round, verbose)\u001b[0m\n\u001b[1;32m   1929\u001b[0m         \u001b[0mround\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         \u001b[0mml_usecase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMLUsecase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSIFICATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1932\u001b[0m     )\n\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mpredict_model\u001b[0;34m(estimator, data, probability_threshold, encoded_labels, raw_score, round, verbose, ml_usecase, display)\u001b[0m\n\u001b[1;32m   8403\u001b[0m     \u001b[0;31m# prediction starts here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8405\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycaret/internal/preprocess.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, y)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;31m# we already know level counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"counts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4513\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4514\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4515\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4516\u001b[0m         )\n\u001b[1;32m   4517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6898\u001b[0m                     \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m                     \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6900\u001b[0;31m                     \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6901\u001b[0m                 )\n\u001b[1;32m   6902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         )\n\u001b[1;32m    671\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_replace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0;31m# in order to avoid repeating the same computations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# GH#38086 faster if we know we dont need to check for regex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0;31m# in order to avoid repeating the same computations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# GH#38086 faster if we know we dont need to check for regex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, mask, regex)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/array_algos/replace.py\u001b[0m in \u001b[0;36mcompare_or_regex_search\u001b[0;34m(a, b, regex, mask)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/array_algos/replace.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         op = np.vectorize(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log = []\n",
    "prediction = predict_model(final_lgbm, data=df_train[FEATS], raw_score = True)\n",
    "print(f\"train : {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n",
    "prediction = predict_model(final_lgbm, data=df_val[FEATS], raw_score = True)\n",
    "print(f\"validation :  {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "1e32d575-2997-4cfd-b717-1007f91cded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : ./0615_0100.csv\n"
     ]
    }
   ],
   "source": [
    "# MAKE PREDICTION\n",
    "# SAVE OUTPUT\n",
    "df_test_shift = df_test[df_test.answerCode == -1]\n",
    "prediction = predict_model(final_lgbm, data=df_test_shift[FEATS], raw_score=True)\n",
    "total_preds = prediction.Score_1.values\n",
    "\n",
    "prediction_name = datetime.now(timezone(timedelta(hours=9))).strftime('%m%d_%H%M')\n",
    "\n",
    "output_dir = './'\n",
    "write_path = os.path.join(output_dir, f\"{prediction_name}.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)    \n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf27eb-f3d2-4368-8c4c-5efc10670b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
